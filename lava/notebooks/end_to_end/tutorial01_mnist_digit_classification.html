<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>MNIST Digit Classification with Lava &mdash; Lava  documentation</title>
      <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../../index.html" class="icon icon-home"> Lava
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../lava_architecture_overview.html">Lava Architecture</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../lava_architecture_overview.html#key-attributes">Key attributes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../lava_architecture_overview.html#why-do-we-need-lava">Why do we need Lava?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../lava_architecture_overview.html#lava-s-foundational-concepts">Lava’s foundational concepts</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../lava_architecture_overview.html#processes">1. Processes:</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava_architecture_overview.html#behavioral-implementations-via-processmodels">2. Behavioral implementations via ProcessModels:</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava_architecture_overview.html#composability-and-connectivity">3. Composability and connectivity:</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava_architecture_overview.html#cross-platform-execution">4. Cross-platform execution:</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../lava_architecture_overview.html#lava-software-stack">Lava software stack</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../getting_started_with_lava.html">Getting Started With Lava</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../getting_started_with_lava.html#application-examples">Application examples:</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../getting_started_with_lava.html#fundamental-concepts">Fundamental concepts:</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../algorithms.html">Algorithms and Application Libraries</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../dl.html">Deep Learning</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../dl.html#introduction">Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../dl.html#lava-dl-workflow">Lava-DL Workflow</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../dl.html#getting-started">Getting Started</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../dl.html#slayer-2-0">SLAYER 2.0</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../dl.html#example-code">Example Code</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../dl.html#bootstrap">Bootstrap</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../dl.html#example-code-1">Example Code</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../dl.html#network-exchange-netx-library">Network Exchange (NetX) Library</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../dl.html#example-code-2">Example Code</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../dl.html#detailed-description">Detailed Description</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-dl/slayer/slayer.html">Lava-DL SLAYER</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-dl/bootstrap/bootstrap.html">Lava-DL Bootstrap</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-dl/netx/netx.html">Lava-DL NetX</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../dnf.html">Dynamic Neural Fields</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../dnf.html#introduction">Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../dnf.html#what-is-lava-dnf">What is lava-dnf?</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../dnf.html#key-features">Key features</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../dnf.html#example">Example</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../optimization.html">Neuromorphic Constraint Optimization Library</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../optimization.html#tutorials">Tutorials</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../optimization.html#qp-solver">QP Solver</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../optimization.html#example">Example</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../optimization.html#id1">QP Solver</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../optimization.html#coming-up-next-cspsolver">Coming up next: CSPSolver</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../optimization.html#requirements">Requirements</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../optimization.html#setup">Setup</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../optimization.html#lava-optimization-documentation">Lava Optimization Documentation</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../developer_guide.html">Developer Guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../developer_guide.html#lava-s-origins">Lava’s Origins</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../developer_guide.html#contact-information">Contact Information</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../developer_guide.html#table-of-contents">Table of Contents</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../developer_guide.html#development-roadmap">Development Roadmap</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../developer_guide.html#initial-release">Initial Release</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../developer_guide.html#how-to-contribute-to-lava">How to contribute to Lava</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../developer_guide.html#open-an-issue">Open an Issue</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../developer_guide.html#pull-request-checklist">Pull Request Checklist</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../developer_guide.html#open-a-pull-request">Open a Pull Request</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../developer_guide.html#coding-conventions">Coding Conventions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../developer_guide.html#code-requirements">Code Requirements</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../developer_guide.html#guidelines">Guidelines</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../developer_guide.html#docstring-format">Docstring Format</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../developer_guide.html#contributors">Contributors</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../developer_guide.html#contributor">Contributor</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../developer_guide.html#committer">Committer</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../developer_guide.html#list-of-lava-nc-lava-project-committers">List of lava-nc/lava Project Committers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../developer_guide.html#list-of-lava-nc-lava-dnf-project-committers">List of lava-nc/lava-dnf Project Committers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../developer_guide.html#list-of-lava-nc-lava-optimization-project-committers">List of lava-nc/lava-optimization Project Committers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../developer_guide.html#list-of-lava-nc-lava-dl-project-committers">List of lava-nc/lava-dl Project Committers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../developer_guide.html#committer-promotion">Committer Promotion</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../developer_guide.html#repository-structure">Repository Structure</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../developer_guide.html#id20">lava-nc/lava</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../developer_guide.html#lava-nc-lava-dnf">lava-nc/lava-dnf</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../developer_guide.html#lava-nc-lava-dl">lava-nc/lava-dl</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../developer_guide.html#lava-nc-lava-optimization">lava-nc/lava-optimization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../developer_guide.html#lava-nc-lava-docs">lava-nc/lava-docs</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../developer_guide.html#code-of-conduct">Code of Conduct</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../developer_guide.html#licenses">Licenses</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../lava_api_documentation.html">Lava API Documentation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../modules.html">lava</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../lava.html">lava package</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../lava.html#subpackages">Subpackages</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../lava.html#module-lava">Module contents</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../lava-lib-dl/index.html">Lava - Deep Learning</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../lava-lib-dl/slayer/index.html">SLAYER</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-dl/slayer/neuron/modules.html">Neuron</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-dl/slayer/synapse/modules.html">Synapse</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-dl/slayer/spike/modules.html">Spike</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-dl/slayer/axon/modules.html">Axon</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-dl/slayer/dendrite/modules.html">Dendrite</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-dl/slayer/block/modules.html">Blocks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-dl/slayer/loss.html">Loss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-dl/slayer/classifier.html">Classifier</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-dl/slayer/io.html">Input/Output</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-dl/slayer/auto.html">Auto</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-dl/slayer/utils/modules.html">Utilities</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava-lib-dl/slayer/index.html#indices-and-tables">Indices and tables</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava-lib-dl/bootstrap/index.html">Bootstrap (ANN-SNN training)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-dl/bootstrap/block/modules.html">Blocks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-dl/bootstrap/ann_sampler.html">ANN Statistics Sampler</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-dl/bootstrap/routine.html">Routine</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava-lib-dl/bootstrap/index.html#indices-and-tables">Indices and tables</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava-lib-dl/netx/index.html">Lava-DL NetX</a></li>
</ul>
</li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">Lava</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>MNIST Digit Classification with Lava</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../_sources/lava/notebooks/end_to_end/tutorial01_mnist_digit_classification.ipynb.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt a.copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<p><em>Copyright (C) 2021 Intel Corporation</em> <em>SPDX-License-Identifier: BSD-3-Clause</em> <em>See: https://spdx.org/licenses/</em></p>
<hr class="docutils" />
<div class="section" id="MNIST-Digit-Classification-with-Lava">
<h1>MNIST Digit Classification with Lava<a class="headerlink" href="#MNIST-Digit-Classification-with-Lava" title="Permalink to this headline"></a></h1>
<p><strong>Motivation</strong><em>: In this tutorial, we will build a Lava Process for an MNIST classifier, using the Lava Processes for LIF neurons and Dense connectivity. Between those leaning towards Neuroscience and those partial to Computer Science, this tutorial aims to be appealing to the former. It is supposed to get one started with Lava in a few minutes.</em></p>
<div class="section" id="This-tutorial-assumes-that-you:">
<h2>This tutorial assumes that you:<a class="headerlink" href="#This-tutorial-assumes-that-you:" title="Permalink to this headline"></a></h2>
<ul class="simple">
<li><p>have the <a class="reference external" href="../in_depth/tutorial01_installing_lava.ipynb">Lava framework installed</a></p></li>
<li><p>are familiar with the <a class="reference external" href="../in_depth/tutorial02_processes.ipynb">Process concept in Lava</a></p></li>
</ul>
</div>
<div class="section" id="This-tutorial-gives-a-bird’s-eye-view-of">
<h2>This tutorial gives a bird’s-eye-view of<a class="headerlink" href="#This-tutorial-gives-a-bird’s-eye-view-of" title="Permalink to this headline"></a></h2>
<ul class="simple">
<li><p>how Lava Process(es) can perform the MNIST digit classification task using <a class="reference external" href="https://github.com/lava-nc/lava/tree/main/lava/proc/lif">Leaky Integrate-and-Fire (LIF)</a> neurons and <a class="reference external" href="https://github.com/lava-nc/lava/tree/main/lava/proc/dense">Dense (fully connected)</a> connectivity.</p></li>
<li><p>how to create a Process</p></li>
<li><p>how to create Python ProcessModels</p></li>
<li><p>how to connect Processes</p></li>
<li><p>how to execute them</p></li>
</ul>
</div>
<div class="section" id="Follow-the-links-below-for-deep-dive-tutorials-on">
<h2>Follow the links below for deep-dive tutorials on<a class="headerlink" href="#Follow-the-links-below-for-deep-dive-tutorials-on" title="Permalink to this headline"></a></h2>
<ul class="simple">
<li><p><a class="reference external" href="../in_depth/tutorial02_processes.ipynb">Processes</a></p></li>
<li><p><a class="reference external" href="../in_depth/tutorial03_process_models.ipynb">ProcessModel</a></p></li>
<li><p><a class="reference external" href="../in_depth/tutorial04_execution.ipynb">Execution</a></p></li>
</ul>
</div>
<div class="section" id="Our-MNIST-Classifier">
<h2>Our MNIST Classifier<a class="headerlink" href="#Our-MNIST-Classifier" title="Permalink to this headline"></a></h2>
<p>In this tutorial, we will build a multi-layer feed-forward classifier without any convolutional layers. The architecture is shown below.</p>
<blockquote>
<div><p><strong>Important Note</strong>:</p>
<p>Right now, this model uses arbitrary <em>untrained</em> network paramters (weights and biases)! We will update this model and fix this shortcoming in the next few days after release. Thus the MNIST classifier is not expected to produce any meaningful output at this point in time. Nevertheless, this example illustrates how to build, compile and run an otherwise functional model in Lava.</p>
</div></blockquote>
<center><p><img alt="Training" src="https://raw.githubusercontent.com/lava-nc/lava-nc.github.io/main/_static/images/tutorial01/mnist_process_arch.png" /></p>
</center><p>flow</p>
<p>The 3 Processes shown above are: 1. Spike Input Process - generates spikes via integrate and fire dynamics, using the image input 2. MNIST Feed-forward process - encapsulates feed-forward architecture of Dense connectivity and LIF neurons 3. Output Process - accumulates output spikes from the feed-forward process and infers the class label; compares the predicted class label with the ground truth</p>
<div class="section" id="General-Imports">
<h3>General Imports<a class="headerlink" href="#General-Imports" title="Permalink to this headline"></a></h3>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span># Assumes: $PYTHONPATH contains lava repository root
import os
import numpy as np
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="Create-the-Process-class">
<h2>Create the Process class<a class="headerlink" href="#Create-the-Process-class" title="Permalink to this headline"></a></h2>
<p>Below we create the Lava Process classes. We need to define only the structure of the process here. The details about how the Process will be executed are specified in the <a class="reference external" href="../in_depth/tutorial03_process_models.ipynb">ProcessModels</a> below.</p>
<p>As mentioned above, we define Processes for - converting input images to binary spikes from those biases (<em>SpikeInput</em>), - the 4-layer fully connected feed-forward network (<em>MnistClassifier</em>) - accumulating the output spikes and inferring the class for an input image (<em>OutputProcess</em>)</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span># Import Process level premitives
from lava.magma.core.process.process import AbstractProcess
from lava.magma.core.process.variable import Var
from lava.magma.core.process.ports.ports import InPort, OutPort
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>class SpikeInput(AbstractProcess):
    &quot;&quot;&quot;Reads image data from the MNIST dataset and converts it to spikes.
    The resulting spike rate is proportional to the pixel value&quot;&quot;&quot;

    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        n_img = kwargs.pop(&#39;num_images&#39;, 25)
        n_steps_img = kwargs.pop(&#39;num_steps_per_image&#39;, 128)
        shape = (784,)
        self.spikes_out = OutPort(shape=shape)
        self.label_out = OutPort(shape=(1,))
        self.num_images = Var(shape=(1,), init=n_img)
        self.num_steps_per_image = Var(shape=(1,), init=n_steps_img)
        self.input_img = Var(shape=shape)
        self.ground_truth_label = Var(shape=(1,))
        self.v = Var(shape=shape, init=0)
        self.vth = Var(shape=(1,), init=kwargs[&#39;vth&#39;])


class MnistClassifier(AbstractProcess):
    &quot;&quot;&quot;A 4 layer feed-forward network with LIF and Dense Processes.&quot;&quot;&quot;

    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        # As mentioned before, the weights and biases saved on the disk are
        # arbitrary numbers. These will not produce any meaningful output
        # classification.
        trained_weights_path = kwargs.pop(&#39;trained_weights_path&#39;, os.path
                                          .join(&#39;.&#39;,&#39;mnist_pretrained.npy&#39;))
        real_path_trained_wgts = os.path.realpath(trained_weights_path)

        wb_list = np.load(real_path_trained_wgts, allow_pickle=True)
        w0 = wb_list[0].transpose().astype(np.int32)
        w1 = wb_list[2].transpose().astype(np.int32)
        w2 = wb_list[4].transpose().astype(np.int32)
        b1 = wb_list[1].astype(np.int32)
        b2 = wb_list[3].astype(np.int32)
        b3 = wb_list[5].astype(np.int32)

        self.spikes_in = InPort(shape=(w0.shape[1],))
        self.spikes_out = OutPort(shape=(w2.shape[0],))
        self.w_dense0 = Var(shape=w0.shape, init=w0)
        self.b_lif1 = Var(shape=(w0.shape[0],), init=b1)
        self.w_dense1 = Var(shape=w1.shape, init=w1)
        self.b_lif2 = Var(shape=(w1.shape[0],), init=b2)
        self.w_dense2 = Var(shape=w2.shape, init=w2)
        self.b_output_lif = Var(shape=(w2.shape[0],), init=b3)


class OutputProcess(AbstractProcess):
    &quot;&quot;&quot;Process to gather spikes from 10 output LIF neurons and interpret the
    highest spiking rate as the classifier output&quot;&quot;&quot;

    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        shape = (10,)
        n_img = kwargs.pop(&#39;num_images&#39;, 25)
        self.num_images = Var(shape=(1,), init=n_img)
        self.spikes_in = InPort(shape=shape)
        self.label_in = InPort(shape=(1,))
        self.spikes_accum = Var(shape=shape)
        self.num_steps_per_image = Var(shape=(1,), init=128)
        self.pred_labels = Var(shape=(n_img,))
        self.gt_labels = Var(shape=(n_img,))
</pre></div>
</div>
</div>
</div>
<div class="section" id="Create-ProcessModels-for-Python-execution">
<h2>Create ProcessModels for Python execution<a class="headerlink" href="#Create-ProcessModels-for-Python-execution" title="Permalink to this headline"></a></h2>
<p>The code in these ProcessModels is what will get executed. Processes above were declarations, in a way.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span># Import parent classes for ProcessModels
from lava.magma.core.model.sub.model import AbstractSubProcessModel
from lava.magma.core.model.py.model import PyLoihiProcessModel

# Import ProcessModel ports, data-types
from lava.magma.core.model.py.ports import PyInPort, PyOutPort
from lava.magma.core.model.py.type import LavaPyType

# Import execution protocol and hardware resources
from lava.magma.core.sync.protocols.loihi_protocol import LoihiProtocol
from lava.magma.core.resources import CPU

# Import decorators
from lava.magma.core.decorator import implements, requires

# Import MNIST dataset
from lava.utils.dataloader.mnist import MnistDataset
np.set_printoptions(linewidth=np.inf)
</pre></div>
</div>
</div>
<div class="section" id="ProcessModel-for-producing-spiking-input">
<h3>ProcessModel for producing spiking input<a class="headerlink" href="#ProcessModel-for-producing-spiking-input" title="Permalink to this headline"></a></h3>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>@implements(proc=SpikeInput, protocol=LoihiProtocol)
@requires(CPU)
class PySpikeInputModel(PyLoihiProcessModel):
    num_images: int = LavaPyType(int, int, precision=32)
    spikes_out: PyOutPort = LavaPyType(PyOutPort.VEC_DENSE, bool, precision=1)
    label_out: PyOutPort = LavaPyType(PyOutPort.VEC_DENSE, np.int32,
                                      precision=32)
    num_steps_per_image: int = LavaPyType(int, int, precision=32)
    input_img: np.ndarray = LavaPyType(np.ndarray, int, precision=32)
    ground_truth_label: int = LavaPyType(int, int, precision=32)
    v: np.ndarray = LavaPyType(np.ndarray, int, precision=32)
    vth: int = LavaPyType(int, int, precision=32)
    mnist_dataset = MnistDataset()
    curr_img_id = -1

    def post_guard(self):
        if self.current_ts % self.num_steps_per_image == 1:
            self.curr_img_id += 1
            return True
        return False

    def run_post_mgmt(self):
        img = self.mnist_dataset.images[self.curr_img_id]
        self.ground_truth_label = self.mnist_dataset.labels[self.curr_img_id]
        self.input_img = img.astype(np.int32) - 127
        self.v = np.zeros(self.v.shape)
        self.label_out.send(np.array([self.ground_truth_label]))

    def run_spk(self):
        self.v[:] = self.v + self.input_img
        s_out = self.v &gt; self.vth
        self.v[s_out] = 0  # reset voltage to 0 after a spike
        self.spikes_out.send(s_out)
</pre></div>
</div>
</div>
</div>
<div class="section" id="ProcessModel-for-the-feed-forward-network">
<h3>ProcessModel for the feed-forward network<a class="headerlink" href="#ProcessModel-for-the-feed-forward-network" title="Permalink to this headline"></a></h3>
<p>Notice that the following process model is further decomposed into sub-Processes, which implement LIF neural dynamics and Dense connectivity. We will not go into the details of how these are implemented in this tutorial.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>from lava.proc.lif.process import LIF
from lava.proc.dense.process import Dense

@implements(MnistClassifier)
@requires(CPU)
class PyMnistClassifierModel(AbstractSubProcessModel):
    spikes_in: PyInPort = LavaPyType(PyInPort.VEC_DENSE, bool, precision=1)
    spikes_out: PyOutPort = LavaPyType(PyOutPort.VEC_DENSE, bool, precision=1)
    w_dense0: np.ndarray = LavaPyType(np.ndarray, int, precision=8)
    b_lif1: np.ndarray = LavaPyType(np.ndarray, int, precision=13)
    w_dense1: np.ndarray = LavaPyType(np.ndarray, int, precision=8)
    b_lif2: np.ndarray = LavaPyType(np.ndarray, int, precision=13)
    w_dense2: np.ndarray = LavaPyType(np.ndarray, int, precision=8)
    b_output_lif: np.ndarray = LavaPyType(np.ndarray, int, precision=13)

    def __init__(self, proc):
        self.dense0 = Dense(shape=(64, 784), weights=proc.w_dense0.init)
        self.lif1 = LIF(shape=(64,), b=proc.b_lif1.init, vth=400,
                        dv=0, du=4095)
        self.dense1 = Dense(shape=(64, 64), weights=proc.w_dense1.init)
        self.lif2 = LIF(shape=(64,), b=proc.b_lif2.init, vth=350,
                        dv=0, du=4095)
        self.dense2 = Dense(shape=(10, 64), weights=proc.w_dense2.init)
        self.output_lif = LIF(shape=(10,), b=proc.b_output_lif.init,
                              vth=2**17-1, dv=0, du=4095)

        proc.in_ports.spikes_in.connect(self.dense0.in_ports.s_in)
        self.dense0.out_ports.a_out.connect(self.lif1.in_ports.a_in)
        self.lif1.out_ports.s_out.connect(self.dense1.in_ports.s_in)
        self.dense1.out_ports.a_out.connect(self.lif2.in_ports.a_in)
        self.lif2.out_ports.s_out.connect(self.dense2.in_ports.s_in)
        self.dense2.out_ports.a_out.connect(self.output_lif.in_ports.a_in)
        self.output_lif.out_ports.s_out.connect(proc.out_ports.spikes_out)
</pre></div>
</div>
</div>
</div>
<div class="section" id="Finally,-ProcessModel-for-inference-output">
<h3>Finally, ProcessModel for inference output<a class="headerlink" href="#Finally,-ProcessModel-for-inference-output" title="Permalink to this headline"></a></h3>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>@implements(proc=OutputProcess, protocol=LoihiProtocol)
@requires(CPU)
class PyOutputProcessModel(PyLoihiProcessModel):
    spikes_in: PyInPort = LavaPyType(PyInPort.VEC_DENSE, bool, precision=1)
    label_in: PyInPort = LavaPyType(PyInPort.VEC_DENSE, int, precision=32)
    num_images: int = LavaPyType(int, int, precision=32)
    spikes_accum: np.ndarray = LavaPyType(np.ndarray, np.int32, precision=32)
    num_steps_per_image: int = LavaPyType(int, int, precision=32)
    pred_labels: np.ndarray = LavaPyType(np.ndarray, int, precision=32)
    gt_labels: np.ndarray = LavaPyType(np.ndarray, int, precision=32)
    current_img_id = -1

    # This is needed for Loihi synchronization protocol
    def post_guard(self):
        if self.current_ts % self.num_steps_per_image == 1 and self\
                .current_ts &gt; 1:
            self.current_img_id += 1
            return True
        return False

    def run_post_mgmt(self):
        print(f&#39;Curr Img: {self.current_img_id}&#39;)
        pred_label = np.argmax(self.spikes_accum)
        self.pred_labels[self.current_img_id] = pred_label
        self.spikes_accum = np.zeros(self.spikes_accum.shape)
        gt_label = self.label_in.recv()
        self.gt_labels[self.current_img_id] = gt_label
        print(f&#39;Pred Label: {pred_label}&#39;, end=&#39;\t&#39;)
        print(f&#39;Ground Truth: {gt_label}&#39;)

    def run_spk(self):
        spikes_buffer = self.spikes_in.recv()
        self.spikes_accum += spikes_buffer
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="Run-the-Process">
<h2>Run the Process<a class="headerlink" href="#Run-the-Process" title="Permalink to this headline"></a></h2>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>num_images = 5
num_steps_per_image = 128

# Create instances
spike_input = SpikeInput(num_images=num_images,
                         num_steps_per_image=num_steps_per_image,
                         vth=1)
mnist_clf = MnistClassifier(
    trained_weights_path=os.path.join(&#39;.&#39;, &#39;mnist_pretrained.npy&#39;))
output_proc = OutputProcess(num_images=num_images)

# Connect instances
spike_input.out_ports.spikes_out.connect(mnist_clf.in_ports.spikes_in)
mnist_clf.out_ports.spikes_out.connect(output_proc.in_ports.spikes_in)
spike_input.out_ports.label_out.connect(output_proc.in_ports.label_in)

from lava.magma.core.run_conditions import RunSteps
from lava.magma.core.run_configs import Loihi1SimCfg

mnist_clf.run(
    condition=RunSteps(num_steps=(num_images+1) * num_steps_per_image),
    run_cfg=Loihi1SimCfg(select_sub_proc_model=True))
mnist_clf.stop()
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Curr Img: 0
Pred Label: 0   Ground Truth: [5]
Curr Img: 1
Pred Label: 0   Ground Truth: [0]
Curr Img: 2
Pred Label: 0   Ground Truth: [4]
Curr Img: 3
Pred Label: 0   Ground Truth: [1]
Curr Img: 4
Pred Label: 0   Ground Truth: [9]
</pre></div></div>
</div>
<blockquote>
<div><p><strong>Important Note</strong>:</p>
<p>Right now, this model uses arbitrary <em>untrained</em> network paramters (weights and biases)! We will update this model and fix this shortcoming in the next few days after release. Thus the MNIST classifier is not expected to produce any meaningful output at this point in time.</p>
</div></blockquote>
<p>If you want to find out more about Lava, have a look at the <a class="reference external" href="https://lava-nc.org/">Lava documentation</a> or dive into the <a class="reference external" href="https://github.com/lava-nc/lava/">source code</a>.</p>
<p>To receive regular updates on the latest developments and releases of the Lava Software Framework please subscribe to the <a class="reference external" href="http://eepurl.com/hJCyhb">INRC newsletter</a>.</p>
</div>
</div>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, Intel Corporation.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(false);
      });
  </script> 

</body>
</html>