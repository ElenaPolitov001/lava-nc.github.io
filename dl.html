<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Lava DL &mdash; Lava  documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Dynamic Neural Fields" href="dnf.html" />
    <link rel="prev" title="Algorithms and Application Libraries" href="algorithms.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> Lava
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="lava_architecture_overview.html">Lava Architecture</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lava_architecture_overview.html#key-attributes">Key attributes</a></li>
<li class="toctree-l2"><a class="reference internal" href="lava_architecture_overview.html#why-do-we-need-lava">Why do we need Lava?</a></li>
<li class="toctree-l2"><a class="reference internal" href="lava_architecture_overview.html#lava-s-foundational-concepts">Lava’s foundational concepts</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lava_architecture_overview.html#processes">1. Processes:</a></li>
<li class="toctree-l3"><a class="reference internal" href="lava_architecture_overview.html#behavioral-implementations-via-processmodels">2. Behavioral implementations via ProcessModels:</a></li>
<li class="toctree-l3"><a class="reference internal" href="lava_architecture_overview.html#composability-and-connectivity">3. Composability and connectivity:</a></li>
<li class="toctree-l3"><a class="reference internal" href="lava_architecture_overview.html#cross-platform-execution">4. Cross-platform execution:</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lava_architecture_overview.html#lava-software-stack">Lava software stack</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="getting_started_with_lava.html">Getting Started With Lava</a><ul>
<li class="toctree-l2"><a class="reference internal" href="getting_started_with_lava.html#application-examples">Application examples:</a></li>
<li class="toctree-l2"><a class="reference internal" href="getting_started_with_lava.html#fundamental-concepts">Fundamental concepts:</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="algorithms.html">Algorithms and Application Libraries</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">Lava DL</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#lava-dl-workflow">Lava-dl Workflow</a></li>
<li class="toctree-l3"><a class="reference internal" href="#lava-lib-dl-slayer">lava.lib.dl.slayer</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#example-code">Example Code</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#lava-lib-dl-netx">lava.lib.dl.netx</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id2">Example Code</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="dnf.html">Dynamic Neural Fields</a><ul>
<li class="toctree-l3"><a class="reference internal" href="dnf.html#introduction">Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="dnf.html#what-is-lava-dnf">What is lava-dnf?</a></li>
<li class="toctree-l3"><a class="reference internal" href="dnf.html#key-features">Key features</a></li>
<li class="toctree-l3"><a class="reference internal" href="dnf.html#example">Example</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="optimization.html">Neuromorphic Constraint Optimization Library</a><ul>
<li class="toctree-l3"><a class="reference internal" href="optimization.html#example">Example</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="developer_guide.html">Developer Guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="developer_guide.html#lava-s-origins">Lava’s Origins</a></li>
<li class="toctree-l2"><a class="reference internal" href="developer_guide.html#contact-information">Contact Information</a></li>
<li class="toctree-l2"><a class="reference internal" href="developer_guide.html#table-of-contents">Table of Contents</a></li>
<li class="toctree-l2"><a class="reference internal" href="developer_guide.html#development-roadmap">Development Roadmap</a><ul>
<li class="toctree-l3"><a class="reference internal" href="developer_guide.html#initial-release">Initial Release</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="developer_guide.html#how-to-contribute-to-lava">How to contribute to Lava</a><ul>
<li class="toctree-l3"><a class="reference internal" href="developer_guide.html#open-an-issue">Open an Issue</a></li>
<li class="toctree-l3"><a class="reference internal" href="developer_guide.html#pull-request-checklist">Pull Request Checklist</a></li>
<li class="toctree-l3"><a class="reference internal" href="developer_guide.html#open-a-pull-request">Open a Pull Request</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="developer_guide.html#coding-conventions">Coding Conventions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="developer_guide.html#code-requirements">Code Requirements</a></li>
<li class="toctree-l3"><a class="reference internal" href="developer_guide.html#guidelines">Guidelines</a></li>
<li class="toctree-l3"><a class="reference internal" href="developer_guide.html#docsting-format">Docsting Format</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="developer_guide.html#contributors">Contributors</a><ul>
<li class="toctree-l3"><a class="reference internal" href="developer_guide.html#contributor">Contributor</a></li>
<li class="toctree-l3"><a class="reference internal" href="developer_guide.html#committer">Committer</a><ul>
<li class="toctree-l4"><a class="reference internal" href="developer_guide.html#list-of-lava-nc-lava-project-committers">List of lava-nc/lava Project Committers</a></li>
<li class="toctree-l4"><a class="reference internal" href="developer_guide.html#list-of-lava-nc-lava-dnf-project-committers">List of lava-nc/lava-dnf Project Committers</a></li>
<li class="toctree-l4"><a class="reference internal" href="developer_guide.html#list-of-lava-nc-lava-optimization-project-committers">List of lava-nc/lava-optimization Project Committers</a></li>
<li class="toctree-l4"><a class="reference internal" href="developer_guide.html#list-of-lava-nc-lava-dl-project-committers">List of lava-nc/lava-dl Project Committers</a></li>
<li class="toctree-l4"><a class="reference internal" href="developer_guide.html#committer-promotion">Committer Promotion</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="developer_guide.html#repository-structure">Repository Structure</a><ul>
<li class="toctree-l3"><a class="reference internal" href="developer_guide.html#id20">lava-nc/lava</a></li>
<li class="toctree-l3"><a class="reference internal" href="developer_guide.html#lava-nc-lava-dnf">lava-nc/lava-dnf</a></li>
<li class="toctree-l3"><a class="reference internal" href="developer_guide.html#lava-nc-lava-dl">lava-nc/lava-dl</a></li>
<li class="toctree-l3"><a class="reference internal" href="developer_guide.html#lava-nc-lava-optimization">lava-nc/lava-optimization</a></li>
<li class="toctree-l3"><a class="reference internal" href="developer_guide.html#lava-nc-lava-docs">lava-nc/lava-docs</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="developer_guide.html#code-of-conduct">Code of Conduct</a></li>
<li class="toctree-l2"><a class="reference internal" href="developer_guide.html#licenses">Licenses</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lava_api_documentation.html">Lava API Documentation</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Lava</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="algorithms.html">Algorithms and Application Libraries</a> &raquo;</li>
      <li>Lava DL</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/dl.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="section" id="lava-dl">
<h1>Lava DL<a class="headerlink" href="#lava-dl" title="Permalink to this headline"></a></h1>
<p><code class="docutils literal notranslate"><span class="pre">lava-dl</span></code> is a library of deep learning tools, which consists of <code class="docutils literal notranslate"><span class="pre">lava.lib.dl.slayer</span></code> and <code class="docutils literal notranslate"><span class="pre">lava.lib.dl.netx</span></code> for training and deployment of event-based deep neural networks on traditional as well as neuromorphic backends.</p>
<div class="section" id="lava-dl-workflow">
<h2>Lava-dl Workflow<a class="headerlink" href="#lava-dl-workflow" title="Permalink to this headline"></a></h2>
<p align="center">
<img src="https://user-images.githubusercontent.com/11490108/135362329-a6cf89e7-9d9e-42e5-9f33-102537463e63.png" alt="Drawing" style="max-height: 400px;"/>
</p></div>
<div class="section" id="lava-lib-dl-slayer">
<h2>lava.lib.dl.slayer<a class="headerlink" href="#lava-lib-dl-slayer" title="Permalink to this headline"></a></h2>
<p><code class="docutils literal notranslate"><span class="pre">lava.lib.dl.slayer</span></code> is an enhanced version of <a class="reference external" href="https://github.com/bamsumit/slayerPytorch">SLAYER</a>. Most noteworthy enhancements are: support for <em>recurrent network structures</em>, a wider variety of <em>neuron models</em> and <em>synaptic connections</em> (a complete list of features is <a class="reference external" href="placeholder_for_slayer_readme">here</a>). This version of SLAYER is built on top of the <a class="reference external" href="https://pytorch.org/">PyTorch</a> deep learning framework, similar to its predecessor. For smooth integration with Lava, <code class="docutils literal notranslate"><span class="pre">lava.lib.dl.slayer</span></code> supports exporting trained models using the platform independent <strong>hdf5 network exchange</strong> format.</p>
<p>In future versions, SLAYER will get completely integrated into Lava to train Lava Processes directly. This will eliminate the need for explicitly exporting and importing the trained networks.</p>
<div class="section" id="example-code">
<h3>Example Code<a class="headerlink" href="#example-code" title="Permalink to this headline"></a></h3>
<p><strong>Import modules</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">lava.lib.dl.slayer</span> <span class="k">as</span> <span class="nn">slayer</span>
</pre></div>
</div>
<p><strong>Network Description</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># like any standard pyTorch network</span>
<span class="k">class</span> <span class="nc">Network</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="o">...</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">blocks</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([</span><span class="c1"># sequential network blocks</span>
                <span class="n">slayer</span><span class="o">.</span><span class="n">block</span><span class="o">.</span><span class="n">sigma_delta</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">sdnn_params</span><span class="p">),</span>
                <span class="n">slayer</span><span class="o">.</span><span class="n">block</span><span class="o">.</span><span class="n">sigma_delta</span><span class="o">.</span><span class="n">Conv</span><span class="p">(</span><span class="n">sdnn_params</span><span class="p">,</span>  <span class="mi">3</span><span class="p">,</span> <span class="mi">24</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
                <span class="n">slayer</span><span class="o">.</span><span class="n">block</span><span class="o">.</span><span class="n">sigma_delta</span><span class="o">.</span><span class="n">Conv</span><span class="p">(</span><span class="n">sdnn_params</span><span class="p">,</span> <span class="mi">24</span><span class="p">,</span> <span class="mi">36</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
                <span class="n">slayer</span><span class="o">.</span><span class="n">block</span><span class="o">.</span><span class="n">rf_iz</span><span class="o">.</span><span class="n">Conv</span><span class="p">(</span><span class="n">rf_params</span><span class="p">,</span> <span class="mi">36</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">delay</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
                <span class="n">slayer</span><span class="o">.</span><span class="n">block</span><span class="o">.</span><span class="n">rf_iz</span><span class="o">.</span><span class="n">Conv</span><span class="p">(</span><span class="n">sdnn_cnn_params</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">delay</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
                <span class="n">slayer</span><span class="o">.</span><span class="n">block</span><span class="o">.</span><span class="n">rf_iz</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>
                <span class="n">slayer</span><span class="o">.</span><span class="n">block</span><span class="o">.</span><span class="n">alif</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">alif_params</span><span class="p">,</span> <span class="mi">64</span><span class="o">*</span><span class="mi">40</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="n">delay</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
                <span class="n">slayer</span><span class="o">.</span><span class="n">block</span><span class="o">.</span><span class="n">cuba</span><span class="o">.</span><span class="n">Recurrent</span><span class="p">(</span><span class="n">cuba_params</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">50</span><span class="p">),</span>
                <span class="n">slayer</span><span class="o">.</span><span class="n">block</span><span class="o">.</span><span class="n">cuba</span><span class="o">.</span><span class="n">KWTA</span><span class="p">(</span><span class="n">cuba_params</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="n">num_winners</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
            <span class="p">])</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">block</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">blocks</span><span class="p">:</span>
            <span class="c1"># forward computation is as simple as calling the blocks in a loop</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">block</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

    <span class="k">def</span> <span class="nf">export_hdf5</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filename</span><span class="p">):</span>
        <span class="c1"># network export to hdf5 format</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">h5py</span><span class="o">.</span><span class="n">File</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span>
        <span class="n">layer</span> <span class="o">=</span> <span class="n">h</span><span class="o">.</span><span class="n">create_group</span><span class="p">(</span><span class="s1">&#39;layer&#39;</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">blocks</span><span class="p">):</span>
            <span class="n">b</span><span class="o">.</span><span class="n">export_hdf5</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">create_group</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">))</span>
</pre></div>
</div>
<p><strong>Training</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">net</span> <span class="o">=</span> <span class="n">Network</span><span class="p">()</span>
<span class="o">...</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">ground_truth</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
        <span class="o">...</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">ground_truth</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">test_loader</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
        <span class="o">...</span>
</pre></div>
</div>
<p><strong>Export the network</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">net</span><span class="o">.</span><span class="n">export_hdf5</span><span class="p">(</span><span class="s1">&#39;network.net&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="lava-lib-dl-netx">
<h2>lava.lib.dl.netx<a class="headerlink" href="#lava-lib-dl-netx" title="Permalink to this headline"></a></h2>
<p>For inference using Lava, <code class="docutils literal notranslate"><span class="pre">lava.lib.dl.netx</span></code> provides an automated API for loading SLAYER-trained models as Lava Processes, which can be directly run on a desired backend. <code class="docutils literal notranslate"><span class="pre">lava.lib.dl.netx</span></code> imports models saved via SLAYER using the hdf5 network exchange format. The details of hdf5 network description specification can be found <a class="reference external" href="placeholder_for_netx_readme">here</a>.</p>
<div class="section" id="id2">
<h3>Example Code<a class="headerlink" href="#id2" title="Permalink to this headline"></a></h3>
<p><strong>Import modules</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">lava.lib.dl.netx</span> <span class="kn">import</span> <span class="n">hdf5</span>
</pre></div>
</div>
<p><strong>Load the trained network</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import the model as a Lava Process</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">hdf5</span><span class="o">.</span><span class="n">Network</span><span class="p">(</span><span class="n">net_config</span><span class="o">=</span><span class="s1">&#39;network.net&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Attach Processes for Input Injection and Output Readout</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">lava.proc.io</span> <span class="kn">import</span> <span class="n">InputLoader</span><span class="p">,</span> <span class="n">BiasWriter</span><span class="p">,</span> <span class="n">OutputReader</span>

<span class="c1"># Instantiate the processes</span>
<span class="n">input_loader</span> <span class="o">=</span> <span class="n">InputLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">testing_set</span><span class="p">)</span>
<span class="n">bias_writer</span> <span class="o">=</span> <span class="n">BiasWriter</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">input_shape</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">OutputReader</span><span class="p">()</span>

<span class="c1"># Connect the input to the network:</span>
<span class="n">input_loader</span><span class="o">.</span><span class="n">data_out</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span><span class="n">bias_writer</span><span class="o">.</span><span class="n">bias_in</span><span class="p">)</span>
<span class="n">bias_writer</span><span class="o">.</span><span class="n">bias_out</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">in_layer</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>

<span class="c1"># Connect network-output to the output process</span>
<span class="n">net</span><span class="o">.</span><span class="n">out_layer</span><span class="o">.</span><span class="n">neuron</span><span class="o">.</span><span class="n">s_out</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">net_output_in</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Run the network</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">lava.magma</span> <span class="kn">import</span> <span class="n">run_configs</span> <span class="k">as</span> <span class="n">rcfg</span>
<span class="kn">from</span> <span class="nn">lava.magma</span> <span class="kn">import</span> <span class="n">run_conditions</span> <span class="k">as</span> <span class="n">rcnd</span>

<span class="n">net</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">condition</span><span class="o">=</span><span class="n">rcnd</span><span class="o">.</span><span class="n">RunSteps</span><span class="p">(</span><span class="n">total_run_time</span><span class="p">),</span> <span class="n">run_cfg</span><span class="o">=</span><span class="n">rcfg</span><span class="o">.</span><span class="n">Loihi1SimCfg</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
</div>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="algorithms.html" class="btn btn-neutral float-left" title="Algorithms and Application Libraries" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="dnf.html" class="btn btn-neutral float-right" title="Dynamic Neural Fields" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, Intel Corporation.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(false);
      });
  </script> 

</body>
</html>