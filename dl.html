

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Lava DL &mdash; Lava  documentation</title>
  

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Dynamic Neural Fields" href="dnf.html" />
    <link rel="prev" title="Algorithms" href="algorithms.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home" alt="Documentation Home"> Lava
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="lava_architecture_overview.html">Lava Architecture Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="lava_api_documentation.html">Lava API Documentation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="magma.html">magma</a><ul>
<li class="toctree-l3"><a class="reference internal" href="magma.html#subpackages">Subpackages</a><ul>
<li class="toctree-l4"><a class="reference internal" href="magma.compiler.html">magma.compiler</a></li>
<li class="toctree-l4"><a class="reference internal" href="magma.core.html">magma.core</a></li>
<li class="toctree-l4"><a class="reference internal" href="magma.runtime.html">magma.runtime</a></li>
<li class="toctree-l4"><a class="reference internal" href="magma.tests.html">magma.tests</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="magma.html#module-magma">Module contents</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="proc.html">proc</a><ul>
<li class="toctree-l3"><a class="reference internal" href="proc.html#subpackages">Subpackages</a><ul>
<li class="toctree-l4"><a class="reference internal" href="proc.conv.html">proc.conv package</a></li>
<li class="toctree-l4"><a class="reference internal" href="proc.dense.html">proc.dense package</a></li>
<li class="toctree-l4"><a class="reference internal" href="proc.io.html">proc.io package</a></li>
<li class="toctree-l4"><a class="reference internal" href="proc.lif.html">proc.lif package</a></li>
<li class="toctree-l4"><a class="reference internal" href="proc.sparse.html">proc.sparse package</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="proc.html#module-proc">Module contents</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="utils.html">utils</a><ul>
<li class="toctree-l3"><a class="reference internal" href="utils.html#subpackages">Subpackages</a><ul>
<li class="toctree-l4"><a class="reference internal" href="utils.fixed-point.html">utils.fixed-point package</a></li>
<li class="toctree-l4"><a class="reference internal" href="utils.profiler.html">utils.profiler package</a></li>
<li class="toctree-l4"><a class="reference internal" href="utils.validator.html">utils.validator package</a></li>
<li class="toctree-l4"><a class="reference internal" href="utils.visualizer.html">utils.visualizer package</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="utils.html#module-utils">Module contents</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="tutorials.html">Tutorials</a><ul>
<li class="toctree-l2"><a class="reference internal" href="tutorials.html#module-tutorials">Module contents</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="algorithms.html">Algorithms</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">Lava DL</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#lava-dl-workflow">Lava-dl Workflow</a></li>
<li class="toctree-l3"><a class="reference internal" href="#lava-lib-dl-slayer">lava.lib.dl.slayer</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#example-code">Example Code</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#lava-lib-dl-netx">lava.lib.dl.netx</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id2">Example Code</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="dnf.html">Dynamic Neural Fields</a><ul>
<li class="toctree-l3"><a class="reference internal" href="dnf.html#introduction">Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="dnf.html#what-is-lava-dnf">What is lava-dnf?</a></li>
<li class="toctree-l3"><a class="reference internal" href="dnf.html#key-features">Key features</a></li>
<li class="toctree-l3"><a class="reference internal" href="dnf.html#example">Example</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="optimization.html">Neuromorphic Constraint Optimization Library</a><ul>
<li class="toctree-l3"><a class="reference internal" href="optimization.html#example">Example</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="developer_guide.html">Developer Guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="developer_guide.html#style-guide-and-conventions">Style guide and conventions</a></li>
<li class="toctree-l2"><a class="reference internal" href="developer_guide.html#how-to-contribute-to-lava">How to contribute to Lava</a></li>
<li class="toctree-l2"><a class="reference internal" href="developer_guide.html#development-roadmap">Development Roadmap</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="loihi_overview.html">Loihi and Loihi Systems Overview</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Lava</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="algorithms.html">Algorithms</a> &raquo;</li>
        
      <li>Lava DL</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/dl.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <section id="lava-dl">
<h1>Lava DL<a class="headerlink" href="#lava-dl" title="Permalink to this headline">¶</a></h1>
<p><code class="docutils literal notranslate"><span class="pre">lava-dl</span></code> is a library of deep learning tools, which consists of <code class="docutils literal notranslate"><span class="pre">lava.lib.dl.slayer</span></code> and <code class="docutils literal notranslate"><span class="pre">lava.lib.dl.netx</span></code> for training and deployment of event-based deep neural networks on traditional as well as neuromorphic backends.</p>
<section id="lava-dl-workflow">
<h2>Lava-dl Workflow<a class="headerlink" href="#lava-dl-workflow" title="Permalink to this headline">¶</a></h2>
<p align="center">
<img src="https://user-images.githubusercontent.com/11490108/135362329-a6cf89e7-9d9e-42e5-9f33-102537463e63.png" alt="Drawing" style="max-height: 400px;"/>
</p></section>
<section id="lava-lib-dl-slayer">
<h2>lava.lib.dl.slayer<a class="headerlink" href="#lava-lib-dl-slayer" title="Permalink to this headline">¶</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">lava.lib.dl.slayer</span></code> is an enhanced version of <a class="reference external" href="https://github.com/bamsumit/slayerPytorch">SLAYER</a>. Most noteworthy enhancements are: support for <em>recurrent network structures</em>, a wider variety of <em>neuron models</em> and <em>synaptic connections</em> (a complete list of features is <a class="reference external" href="placeholder_for_slayer_readme">here</a>). This version of SLAYER is built on top of the <a class="reference external" href="https://pytorch.org/">PyTorch</a> deep learning framework, similar to its predecessor. For smooth integration with Lava, <code class="docutils literal notranslate"><span class="pre">lava.lib.dl.slayer</span></code> supports exporting trained models using the platform independent <strong>hdf5 network exchange</strong> format.</p>
<p>In future versions, SLAYER will get completely integrated into Lava to train Lava Processes directly. This will eliminate the need for explicitly exporting and importing the trained networks.</p>
<section id="example-code">
<h3>Example Code<a class="headerlink" href="#example-code" title="Permalink to this headline">¶</a></h3>
<p><strong>Import modules</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">lava.lib.dl.slayer</span> <span class="k">as</span> <span class="nn">slayer</span>
</pre></div>
</div>
<p><strong>Network Description</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># like any standard pyTorch network</span>
<span class="k">class</span> <span class="nc">Network</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="o">...</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">blocks</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([</span><span class="c1"># sequential network blocks</span>
                <span class="n">slayer</span><span class="o">.</span><span class="n">block</span><span class="o">.</span><span class="n">sigma_delta</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">sdnn_params</span><span class="p">),</span>
                <span class="n">slayer</span><span class="o">.</span><span class="n">block</span><span class="o">.</span><span class="n">sigma_delta</span><span class="o">.</span><span class="n">Conv</span><span class="p">(</span><span class="n">sdnn_params</span><span class="p">,</span>  <span class="mi">3</span><span class="p">,</span> <span class="mi">24</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
                <span class="n">slayer</span><span class="o">.</span><span class="n">block</span><span class="o">.</span><span class="n">sigma_delta</span><span class="o">.</span><span class="n">Conv</span><span class="p">(</span><span class="n">sdnn_params</span><span class="p">,</span> <span class="mi">24</span><span class="p">,</span> <span class="mi">36</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
                <span class="n">slayer</span><span class="o">.</span><span class="n">block</span><span class="o">.</span><span class="n">rf_iz</span><span class="o">.</span><span class="n">Conv</span><span class="p">(</span><span class="n">rf_params</span><span class="p">,</span> <span class="mi">36</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">delay</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
                <span class="n">slayer</span><span class="o">.</span><span class="n">block</span><span class="o">.</span><span class="n">rf_iz</span><span class="o">.</span><span class="n">Conv</span><span class="p">(</span><span class="n">sdnn_cnn_params</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">delay</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
                <span class="n">slayer</span><span class="o">.</span><span class="n">block</span><span class="o">.</span><span class="n">rf_iz</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>
                <span class="n">slayer</span><span class="o">.</span><span class="n">block</span><span class="o">.</span><span class="n">alif</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">alif_params</span><span class="p">,</span> <span class="mi">64</span><span class="o">*</span><span class="mi">40</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="n">delay</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
                <span class="n">slayer</span><span class="o">.</span><span class="n">block</span><span class="o">.</span><span class="n">cuba</span><span class="o">.</span><span class="n">Recurrent</span><span class="p">(</span><span class="n">cuba_params</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">50</span><span class="p">),</span>
                <span class="n">slayer</span><span class="o">.</span><span class="n">block</span><span class="o">.</span><span class="n">cuba</span><span class="o">.</span><span class="n">KWTA</span><span class="p">(</span><span class="n">cuba_params</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="n">num_winners</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
            <span class="p">])</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">block</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">blocks</span><span class="p">:</span>
            <span class="c1"># forward computation is as simple as calling the blocks in a loop</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">block</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

    <span class="k">def</span> <span class="nf">export_hdf5</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filename</span><span class="p">):</span>
        <span class="c1"># network export to hdf5 format</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">h5py</span><span class="o">.</span><span class="n">File</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span>
        <span class="n">layer</span> <span class="o">=</span> <span class="n">h</span><span class="o">.</span><span class="n">create_group</span><span class="p">(</span><span class="s1">&#39;layer&#39;</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">blocks</span><span class="p">):</span>
            <span class="n">b</span><span class="o">.</span><span class="n">export_hdf5</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">create_group</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">))</span>
</pre></div>
</div>
<p><strong>Training</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">net</span> <span class="o">=</span> <span class="n">Network</span><span class="p">()</span>
<span class="o">...</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">ground_truth</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
        <span class="o">...</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">ground_truth</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">test_loader</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
        <span class="o">...</span>
</pre></div>
</div>
<p><strong>Export the network</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">net</span><span class="o">.</span><span class="n">export_hdf5</span><span class="p">(</span><span class="s1">&#39;network.net&#39;</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="lava-lib-dl-netx">
<h2>lava.lib.dl.netx<a class="headerlink" href="#lava-lib-dl-netx" title="Permalink to this headline">¶</a></h2>
<p>For inference using Lava, <code class="docutils literal notranslate"><span class="pre">lava.lib.dl.netx</span></code> provides an automated API for loading SLAYER-trained models as Lava Processes, which can be directly run on a desired backend. <code class="docutils literal notranslate"><span class="pre">lava.lib.dl.netx</span></code> imports models saved via SLAYER using the hdf5 network exchange format. The details of hdf5 network description specification can be found <a class="reference external" href="placeholder_for_netx_readme">here</a>.</p>
<section id="id2">
<h3>Example Code<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h3>
<p><strong>Import modules</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">lava.lib.dl.netx</span> <span class="kn">import</span> <span class="n">hdf5</span>
</pre></div>
</div>
<p><strong>Load the trained network</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import the model as a Lava Process</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">hdf5</span><span class="o">.</span><span class="n">Network</span><span class="p">(</span><span class="n">net_config</span><span class="o">=</span><span class="s1">&#39;network.net&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Attach Processes for Input Injection and Output Readout</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">lava.proc.io</span> <span class="kn">import</span> <span class="n">InputLoader</span><span class="p">,</span> <span class="n">BiasWriter</span><span class="p">,</span> <span class="n">OutputReader</span>

<span class="c1"># Instantiate the processes</span>
<span class="n">input_loader</span> <span class="o">=</span> <span class="n">InputLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">testing_set</span><span class="p">)</span>
<span class="n">bias_writer</span> <span class="o">=</span> <span class="n">BiasWriter</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">input_shape</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">OutputReader</span><span class="p">()</span>

<span class="c1"># Connect the input to the network:</span>
<span class="n">input_loader</span><span class="o">.</span><span class="n">data_out</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span><span class="n">bias_writer</span><span class="o">.</span><span class="n">bias_in</span><span class="p">)</span>
<span class="n">bias_writer</span><span class="o">.</span><span class="n">bias_out</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">in_layer</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>

<span class="c1"># Connect network-output to the output process</span>
<span class="n">net</span><span class="o">.</span><span class="n">out_layer</span><span class="o">.</span><span class="n">neuron</span><span class="o">.</span><span class="n">s_out</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">net_output_in</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Run the network</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">lava.magma</span> <span class="kn">import</span> <span class="n">run_configs</span> <span class="k">as</span> <span class="n">rcfg</span>
<span class="kn">from</span> <span class="nn">lava.magma</span> <span class="kn">import</span> <span class="n">run_conditions</span> <span class="k">as</span> <span class="n">rcnd</span>

<span class="n">net</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">condition</span><span class="o">=</span><span class="n">rcnd</span><span class="o">.</span><span class="n">RunSteps</span><span class="p">(</span><span class="n">total_run_time</span><span class="p">),</span> <span class="n">run_cfg</span><span class="o">=</span><span class="n">rcfg</span><span class="o">.</span><span class="n">Loihi1SimCfg</span><span class="p">())</span>
</pre></div>
</div>
</section>
</section>
</section>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="dnf.html" class="btn btn-neutral float-right" title="Dynamic Neural Fields" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="algorithms.html" class="btn btn-neutral float-left" title="Algorithms" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright 2021, Intel Corporation

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(false);
      });
  </script>

  
  
    
   

</body>
</html>