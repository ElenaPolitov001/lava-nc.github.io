<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Deep Learning &mdash; Lava  documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Lava-DL SLAYER" href="lava-lib-dl/slayer/slayer.html" />
    <link rel="prev" title="Algorithms and Application Libraries" href="algorithms.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> Lava
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="lava_architecture_overview.html">Lava Architecture</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lava_architecture_overview.html#key-attributes">Key attributes</a></li>
<li class="toctree-l2"><a class="reference internal" href="lava_architecture_overview.html#why-do-we-need-lava">Why do we need Lava?</a></li>
<li class="toctree-l2"><a class="reference internal" href="lava_architecture_overview.html#lava-s-foundational-concepts">Lava’s foundational concepts</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lava_architecture_overview.html#processes">1. Processes:</a></li>
<li class="toctree-l3"><a class="reference internal" href="lava_architecture_overview.html#behavioral-implementations-via-processmodels">2. Behavioral implementations via ProcessModels:</a></li>
<li class="toctree-l3"><a class="reference internal" href="lava_architecture_overview.html#composability-and-connectivity">3. Composability and connectivity:</a></li>
<li class="toctree-l3"><a class="reference internal" href="lava_architecture_overview.html#cross-platform-execution">4. Cross-platform execution:</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lava_architecture_overview.html#lava-software-stack">Lava software stack</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="getting_started_with_lava.html">Getting Started With Lava</a><ul>
<li class="toctree-l2"><a class="reference internal" href="getting_started_with_lava.html#application-examples">Application examples:</a></li>
<li class="toctree-l2"><a class="reference internal" href="getting_started_with_lava.html#fundamental-concepts">Fundamental concepts:</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="algorithms.html">Algorithms and Application Libraries</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">Deep Learning</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#introduction">Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="#lava-dl-workflow">Lava-DL Workflow</a></li>
<li class="toctree-l3"><a class="reference internal" href="#getting-started">Getting Started</a></li>
<li class="toctree-l3"><a class="reference internal" href="#slayer-2-0">SLAYER 2.0</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#example-code">Example Code</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#bootstrap">Bootstrap</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#example-code-1">Example Code</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#network-exchange-netx-library">Network Exchange (NetX) Library</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#example-code-2">Example Code</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#detailed-description">Detailed Description</a><ul>
<li class="toctree-l4"><a class="reference internal" href="lava-lib-dl/slayer/slayer.html">Lava-DL SLAYER</a></li>
<li class="toctree-l4"><a class="reference internal" href="lava-lib-dl/bootstrap/bootstrap.html">Lava-DL Bootstrap</a></li>
<li class="toctree-l4"><a class="reference internal" href="lava-lib-dl/netx/netx.html">Lava-DL NetX</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="dnf.html">Dynamic Neural Fields</a><ul>
<li class="toctree-l3"><a class="reference internal" href="dnf.html#introduction">Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="dnf.html#what-is-lava-dnf">What is lava-dnf?</a></li>
<li class="toctree-l3"><a class="reference internal" href="dnf.html#key-features">Key features</a></li>
<li class="toctree-l3"><a class="reference internal" href="dnf.html#example">Example</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="optimization.html">Neuromorphic Constraint Optimization</a><ul>
<li class="toctree-l3"><a class="reference internal" href="optimization.html#tutorials">Tutorials</a><ul>
<li class="toctree-l4"><a class="reference internal" href="optimization.html#qp-solver">QP Solver</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="optimization.html#example">Example</a><ul>
<li class="toctree-l4"><a class="reference internal" href="optimization.html#id1">QP Solver</a></li>
<li class="toctree-l4"><a class="reference internal" href="optimization.html#coming-up-next-cspsolver">Coming up next: CSPSolver</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="optimization.html#requirements">Requirements</a></li>
<li class="toctree-l3"><a class="reference internal" href="optimization.html#setup">Setup</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="developer_guide.html">Developer Guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="developer_guide.html#lava-s-origins">Lava’s Origins</a></li>
<li class="toctree-l2"><a class="reference internal" href="developer_guide.html#contact-information">Contact Information</a></li>
<li class="toctree-l2"><a class="reference internal" href="developer_guide.html#table-of-contents">Table of Contents</a></li>
<li class="toctree-l2"><a class="reference internal" href="developer_guide.html#development-roadmap">Development Roadmap</a><ul>
<li class="toctree-l3"><a class="reference internal" href="developer_guide.html#initial-release">Initial Release</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="developer_guide.html#how-to-contribute-to-lava">How to contribute to Lava</a><ul>
<li class="toctree-l3"><a class="reference internal" href="developer_guide.html#open-an-issue">Open an Issue</a></li>
<li class="toctree-l3"><a class="reference internal" href="developer_guide.html#pull-request-checklist">Pull Request Checklist</a></li>
<li class="toctree-l3"><a class="reference internal" href="developer_guide.html#open-a-pull-request">Open a Pull Request</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="developer_guide.html#coding-conventions">Coding Conventions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="developer_guide.html#code-requirements">Code Requirements</a></li>
<li class="toctree-l3"><a class="reference internal" href="developer_guide.html#guidelines">Guidelines</a></li>
<li class="toctree-l3"><a class="reference internal" href="developer_guide.html#docstring-format">Docstring Format</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="developer_guide.html#contributors">Contributors</a><ul>
<li class="toctree-l3"><a class="reference internal" href="developer_guide.html#contributor">Contributor</a></li>
<li class="toctree-l3"><a class="reference internal" href="developer_guide.html#committer">Committer</a><ul>
<li class="toctree-l4"><a class="reference internal" href="developer_guide.html#list-of-lava-nc-lava-project-committers">List of lava-nc/lava Project Committers</a></li>
<li class="toctree-l4"><a class="reference internal" href="developer_guide.html#list-of-lava-nc-lava-dnf-project-committers">List of lava-nc/lava-dnf Project Committers</a></li>
<li class="toctree-l4"><a class="reference internal" href="developer_guide.html#list-of-lava-nc-lava-optimization-project-committers">List of lava-nc/lava-optimization Project Committers</a></li>
<li class="toctree-l4"><a class="reference internal" href="developer_guide.html#list-of-lava-nc-lava-dl-project-committers">List of lava-nc/lava-dl Project Committers</a></li>
<li class="toctree-l4"><a class="reference internal" href="developer_guide.html#committer-promotion">Committer Promotion</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="developer_guide.html#repository-structure">Repository Structure</a><ul>
<li class="toctree-l3"><a class="reference internal" href="developer_guide.html#id20">lava-nc/lava</a></li>
<li class="toctree-l3"><a class="reference internal" href="developer_guide.html#lava-nc-lava-dnf">lava-nc/lava-dnf</a></li>
<li class="toctree-l3"><a class="reference internal" href="developer_guide.html#lava-nc-lava-dl">lava-nc/lava-dl</a></li>
<li class="toctree-l3"><a class="reference internal" href="developer_guide.html#lava-nc-lava-optimization">lava-nc/lava-optimization</a></li>
<li class="toctree-l3"><a class="reference internal" href="developer_guide.html#lava-nc-lava-docs">lava-nc/lava-docs</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="developer_guide.html#code-of-conduct">Code of Conduct</a></li>
<li class="toctree-l2"><a class="reference internal" href="developer_guide.html#licenses">Licenses</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lava_api_documentation.html">Lava API Documentation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lava/modules.html">Lava</a></li>
<li class="toctree-l2"><a class="reference internal" href="lava-lib-dl/index.html">Lava - Deep Learning</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lava-lib-dl/slayer/index.html">SLAYER</a><ul>
<li class="toctree-l4"><a class="reference internal" href="lava-lib-dl/slayer/neuron/modules.html">Neuron</a></li>
<li class="toctree-l4"><a class="reference internal" href="lava-lib-dl/slayer/synapse/modules.html">Synapse</a></li>
<li class="toctree-l4"><a class="reference internal" href="lava-lib-dl/slayer/spike/modules.html">Spike</a></li>
<li class="toctree-l4"><a class="reference internal" href="lava-lib-dl/slayer/axon/modules.html">Axon</a></li>
<li class="toctree-l4"><a class="reference internal" href="lava-lib-dl/slayer/dendrite/modules.html">Dendrite</a></li>
<li class="toctree-l4"><a class="reference internal" href="lava-lib-dl/slayer/block/modules.html">Blocks</a></li>
<li class="toctree-l4"><a class="reference internal" href="lava-lib-dl/slayer/loss.html">Loss</a></li>
<li class="toctree-l4"><a class="reference internal" href="lava-lib-dl/slayer/classifier.html">Classifier</a></li>
<li class="toctree-l4"><a class="reference internal" href="lava-lib-dl/slayer/io.html">Input/Output</a></li>
<li class="toctree-l4"><a class="reference internal" href="lava-lib-dl/slayer/auto.html">Auto</a></li>
<li class="toctree-l4"><a class="reference internal" href="lava-lib-dl/slayer/utils/modules.html">Utilities</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="lava-lib-dl/slayer/index.html#indices-and-tables">Indices and tables</a></li>
<li class="toctree-l3"><a class="reference internal" href="lava-lib-dl/bootstrap/index.html">Bootstrap (ANN-SNN training)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="lava-lib-dl/bootstrap/block/modules.html">Blocks</a></li>
<li class="toctree-l4"><a class="reference internal" href="lava-lib-dl/bootstrap/ann_sampler.html">ANN Statistics Sampler</a></li>
<li class="toctree-l4"><a class="reference internal" href="lava-lib-dl/bootstrap/routine.html">Routine</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="lava-lib-dl/bootstrap/index.html#indices-and-tables">Indices and tables</a></li>
<li class="toctree-l3"><a class="reference internal" href="lava-lib-dl/netx/index.html">Lava-DL NetX</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lava-lib-optimization/index.html">Lava - Optimization</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Lava</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="algorithms.html">Algorithms and Application Libraries</a> &raquo;</li>
      <li>Deep Learning</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/dl.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="deep-learning">
<h1>Deep Learning<a class="headerlink" href="#deep-learning" title="Permalink to this headline"></a></h1>
<div class="section" id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline"></a></h2>
<p>Lava-DL (<code class="docutils literal notranslate"><span class="pre">lava-dl</span></code>) is a library of deep learning tools within Lava that
support offline training, online training and inference methods for
various Deep Event-Based Networks.</p>
<p>There are two main strategies for training Deep Event-Based Networks:
<em>direct training</em> and <em>ANN to SNN converison</em>.</p>
<p>Directly training the network utilizes the information of precise timing of events. Direct training is very accurate and results in efficient networks. However, directly training networks take a lot of time and resources.</p>
<p>On the other hand, ANN to SNN conversion is especially suitable for rate
coded SNNs where we can leverage the fast training of ANN. These
converted SNNs, however, require increased latency compared to directly
trained SNNs.</p>
<p>Lava-DL provides an improved version of
<a class="reference external" href="https://github.com/bamsumit/slayerPytorch">SLAYER</a> for direct
training of deep event based networks and a new ANN-SNN accelerated
training approach called <a class="reference external" href="lava-lib-dl/bootstrap/bootstrap.html">Bootstrap</a> to mitigate high latency issue of conventional ANN-SNN methods for training Deep
Event-Based Networks.</p>
<p>The lava-dl training libraries are independent of the core lava library since Lava Processes cannot be trained directly at this point. Instead, lava-dl is first used to train the model which can then be converted to a network of Lava processes using the netx library using platform independent hdf5 network description.</p>
<p>The library presently consists of</p>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">lava.lib.dl.slayer</span></code> for natively training Deep Event-Based
Networks.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">lava.lib.dl.bootstrap</span></code> for training rate coded SNNs.</p></li>
</ol>
<p>Coming soon to the library 1. <code class="docutils literal notranslate"><span class="pre">lava.lib.dl.netx</span></code> for training and
deployment of event-based deep neural networks on traditional as well as
neuromorphic backends.</p>
<p>More tools will be added in the future.</p>
</div>
<div class="section" id="lava-dl-workflow">
<h2>Lava-DL Workflow<a class="headerlink" href="#lava-dl-workflow" title="Permalink to this headline"></a></h2>
<p align="center">
<img src="https://user-images.githubusercontent.com/29907126/140595634-a97886c6-280a-4771-830b-ae47a9324612.png" alt="Drawing" style="max-height: 400px;"/>
</p><p>Typical Lava-DL workflow consists of:</p>
<ul class="simple">
<li><p><strong>Training:</strong> using
<code class="docutils literal notranslate"><span class="pre">lava.lib.dl.{slayer/bootstrap}</span></code> which results in a <em>hdf5 network
description</em>. Training usually consists of iterative cycle of
architecture design, hyperparameter tuning, and backpropagation
training.</p></li>
<li><p><strong>Inference:</strong> using <code class="docutils literal notranslate"><span class="pre">lava.lib.dl.netx</span></code> which generates
lava proces from the hdf5 network description of the trained network and
enables inference on different backends.</p></li>
</ul>
</div>
<div class="section" id="getting-started">
<h2>Getting Started<a class="headerlink" href="#getting-started" title="Permalink to this headline"></a></h2>
<p><strong>End to end tutorials</strong></p>
<ul class="simple">
<li><p><a class="reference external" href="lava-lib-dl/slayer/notebooks/oxford/train.html">Oxford spike train regression</a></p></li>
<li><p><a class="reference external" href="lava-lib-dl/bootstrap/notebooks/mnist/train.html">MNIST digit classification</a></p></li>
<li><p><a class="reference external" href="lava-lib-dl/slayer/notebooks/nmnist/train.html">NMNIST digit classification</a></p></li>
<li><p><a class="reference external" href="lava-lib-dl/slayer/notebooks/pilotnet/train.html">PilotNet steering angle prediction</a></p></li>
</ul>
<p><strong>Deep dive tutorials</strong></p>
<ul class="simple">
<li><p><a class="reference external" href="lava-lib-dl/slayer/notebooks/neuron_dynamics/dynamics.html">Dynamics and Neurons</a></p></li>
</ul>
</div>
<div class="section" id="slayer-2-0">
<h2>SLAYER 2.0<a class="headerlink" href="#slayer-2-0" title="Permalink to this headline"></a></h2>
<p>SLAYER 2.0 (<cite>lava.lib.dl.slayer</cite>) is an enhanced version of
<a class="reference external" href="https://github.com/bamsumit/slayerPytorch">SLAYER</a>. Most noteworthy
enhancements are: support for <em>recurrent network structures</em>, a wider
variety of <em>neuron models</em> and <em>synaptic connections</em> (a complete list
of features is
<a class="reference external" href="lava-lib-dl/slayer/slayer.html">here</a>).
This version of SLAYER is built on top of the
<a class="reference external" href="https://pytorch.org/">PyTorch</a> deep learning framework, similar to
its predecessor. For smooth integration with Lava,
<cite>lava.lib.dl.slayer</cite> supports exporting trained models using the
platform independent <strong>hdf5 network exchange</strong> format.</p>
<p>In future versions, SLAYER will get completely integrated into Lava to
train Lava Processes directly. This will eliminate the need for
explicitly exporting and importing the trained networks.</p>
<div class="section" id="example-code">
<h3>Example Code<a class="headerlink" href="#example-code" title="Permalink to this headline"></a></h3>
<p><strong>Import modules</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">lava.lib.dl.slayer</span> <span class="k">as</span> <span class="nn">slayer</span>
</pre></div>
</div>
<p><strong>Network Description</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># like any standard pyTorch network</span>
<span class="k">class</span> <span class="nc">Network</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="o">...</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">blocks</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([</span><span class="c1"># sequential network blocks</span>
                <span class="n">slayer</span><span class="o">.</span><span class="n">block</span><span class="o">.</span><span class="n">sigma_delta</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">sdnn_params</span><span class="p">),</span>
                <span class="n">slayer</span><span class="o">.</span><span class="n">block</span><span class="o">.</span><span class="n">sigma_delta</span><span class="o">.</span><span class="n">Conv</span><span class="p">(</span><span class="n">sdnn_params</span><span class="p">,</span>  <span class="mi">3</span><span class="p">,</span> <span class="mi">24</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
                <span class="n">slayer</span><span class="o">.</span><span class="n">block</span><span class="o">.</span><span class="n">sigma_delta</span><span class="o">.</span><span class="n">Conv</span><span class="p">(</span><span class="n">sdnn_params</span><span class="p">,</span> <span class="mi">24</span><span class="p">,</span> <span class="mi">36</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
                <span class="n">slayer</span><span class="o">.</span><span class="n">block</span><span class="o">.</span><span class="n">rf_iz</span><span class="o">.</span><span class="n">Conv</span><span class="p">(</span><span class="n">rf_params</span><span class="p">,</span> <span class="mi">36</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">delay</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
                <span class="n">slayer</span><span class="o">.</span><span class="n">block</span><span class="o">.</span><span class="n">rf_iz</span><span class="o">.</span><span class="n">Conv</span><span class="p">(</span><span class="n">sdnn_cnn_params</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">delay</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
                <span class="n">slayer</span><span class="o">.</span><span class="n">block</span><span class="o">.</span><span class="n">rf_iz</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>
                <span class="n">slayer</span><span class="o">.</span><span class="n">block</span><span class="o">.</span><span class="n">alif</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">alif_params</span><span class="p">,</span> <span class="mi">64</span><span class="o">*</span><span class="mi">40</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="n">delay</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
                <span class="n">slayer</span><span class="o">.</span><span class="n">block</span><span class="o">.</span><span class="n">cuba</span><span class="o">.</span><span class="n">Recurrent</span><span class="p">(</span><span class="n">cuba_params</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">50</span><span class="p">),</span>
                <span class="n">slayer</span><span class="o">.</span><span class="n">block</span><span class="o">.</span><span class="n">cuba</span><span class="o">.</span><span class="n">KWTA</span><span class="p">(</span><span class="n">cuba_params</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="n">num_winners</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
            <span class="p">])</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">block</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">blocks</span><span class="p">:</span>
            <span class="c1"># forward computation is as simple as calling the blocks in a loop</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">block</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

    <span class="k">def</span> <span class="nf">export_hdf5</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filename</span><span class="p">):</span>
        <span class="c1"># network export to hdf5 format</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">h5py</span><span class="o">.</span><span class="n">File</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span>
        <span class="n">layer</span> <span class="o">=</span> <span class="n">h</span><span class="o">.</span><span class="n">create_group</span><span class="p">(</span><span class="s1">&#39;layer&#39;</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">blocks</span><span class="p">):</span>
            <span class="n">b</span><span class="o">.</span><span class="n">export_hdf5</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">create_group</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">))</span>
</pre></div>
</div>
<p><strong>Training</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">net</span> <span class="o">=</span> <span class="n">Network</span><span class="p">()</span>
<span class="n">assistant</span> <span class="o">=</span> <span class="n">slayer</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">Assistant</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">error</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">stats</span><span class="p">)</span>
<span class="o">...</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">ground_truth</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">assistant</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">ground_truth</span><span class="p">)</span>
        <span class="o">...</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">ground_truth</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">test_loader</span><span class="p">):</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">assistant</span><span class="o">.</span><span class="n">test</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">ground_truth</span><span class="p">)</span>
        <span class="o">...</span>
</pre></div>
</div>
<p><strong>Export the network</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">net</span><span class="o">.</span><span class="n">export_hdf5</span><span class="p">(</span><span class="s1">&#39;network.net&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="bootstrap">
<h2>Bootstrap<a class="headerlink" href="#bootstrap" title="Permalink to this headline"></a></h2>
<p>In general ANN-SNN conversion methods for rate based SNN result in high latency of the network during inference. This is because the rate interpretation of a spiking neuron using ReLU acitvation unit breaks down for short inference times. As a result, the network requires many time steps per sample to achieve adequate inference results.</p>
<p>Bootstrap (<cite>lava.lib.dl.bootstrap</cite>) enables rapid training of rate based SNNs by translating them to an equivalent dynamic ANN representation which leads to SNN performance close to the equivalent ANN and low latency inference. More details <a class="reference external" href="lava-lib-dl/bootstrap/bootstrap.html">here</a>. It also supports <em>hybrid training</em>
a mixed ANN-SNN network to minimize the ANN to SNN performance gap. This method is independent of the SNN model being used.</p>
<p>It has similar API as <cite>lava.lib.dl.slayer</cite> and supports exporting
trained models using the platform independent <strong>hdf5 network exchange</strong>
format.</p>
<div class="section" id="example-code-1">
<span id="id1"></span><h3>Example Code<a class="headerlink" href="#example-code-1" title="Permalink to this headline"></a></h3>
<p><strong>Import modules</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">lava.lib.dl.bootstrap</span> <span class="k">as</span> <span class="nn">bootstrap</span>
</pre></div>
</div>
<p><strong>Network Description</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># like any standard pyTorch network</span>
<span class="k">class</span> <span class="nc">Network</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="o">...</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">blocks</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([</span><span class="c1"># sequential network blocks</span>
                <span class="n">bootstrap</span><span class="o">.</span><span class="n">block</span><span class="o">.</span><span class="n">cuba</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">sdnn_params</span><span class="p">),</span>
                <span class="n">bootstrap</span><span class="o">.</span><span class="n">block</span><span class="o">.</span><span class="n">cuba</span><span class="o">.</span><span class="n">Conv</span><span class="p">(</span><span class="n">sdnn_params</span><span class="p">,</span>  <span class="mi">3</span><span class="p">,</span> <span class="mi">24</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
                <span class="n">bootstrap</span><span class="o">.</span><span class="n">block</span><span class="o">.</span><span class="n">cuba</span><span class="o">.</span><span class="n">Conv</span><span class="p">(</span><span class="n">sdnn_params</span><span class="p">,</span> <span class="mi">24</span><span class="p">,</span> <span class="mi">36</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
                <span class="n">bootstrap</span><span class="o">.</span><span class="n">block</span><span class="o">.</span><span class="n">cuba</span><span class="o">.</span><span class="n">Conv</span><span class="p">(</span><span class="n">rf_params</span><span class="p">,</span> <span class="mi">36</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
                <span class="n">bootstrap</span><span class="o">.</span><span class="n">block</span><span class="o">.</span><span class="n">cuba</span><span class="o">.</span><span class="n">Conv</span><span class="p">(</span><span class="n">sdnn_cnn_params</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
                <span class="n">bootstrap</span><span class="o">.</span><span class="n">block</span><span class="o">.</span><span class="n">cuba</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>
                <span class="n">bootstrap</span><span class="o">.</span><span class="n">block</span><span class="o">.</span><span class="n">cuba</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">alif_params</span><span class="p">,</span> <span class="mi">64</span><span class="o">*</span><span class="mi">40</span><span class="p">,</span> <span class="mi">100</span><span class="p">),</span>
                <span class="n">bootstrap</span><span class="o">.</span><span class="n">block</span><span class="o">.</span><span class="n">cuba</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">cuba_params</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
            <span class="p">])</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">mode</span><span class="p">):</span>
        <span class="o">...</span>
        <span class="k">for</span> <span class="n">block</span><span class="p">,</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">blocks</span><span class="p">,</span> <span class="n">mode</span><span class="p">):</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">block</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="n">m</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">x</span>

    <span class="k">def</span> <span class="nf">export_hdf5</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filename</span><span class="p">):</span>
        <span class="c1"># network export to hdf5 format</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">h5py</span><span class="o">.</span><span class="n">File</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span>
        <span class="n">layer</span> <span class="o">=</span> <span class="n">h</span><span class="o">.</span><span class="n">create_group</span><span class="p">(</span><span class="s1">&#39;layer&#39;</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">blocks</span><span class="p">):</span>
            <span class="n">b</span><span class="o">.</span><span class="n">export_hdf5</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">create_group</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">))</span>
</pre></div>
</div>
<p><strong>Training</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">net</span> <span class="o">=</span> <span class="n">Network</span><span class="p">()</span>
<span class="n">scheduler</span> <span class="o">=</span> <span class="n">bootstrap</span><span class="o">.</span><span class="n">routine</span><span class="o">.</span><span class="n">Scheduler</span><span class="p">()</span>
<span class="o">...</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">ground_truth</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
        <span class="n">mode</span> <span class="o">=</span> <span class="n">scheduler</span><span class="o">.</span><span class="n">mode</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">net</span><span class="o">.</span><span class="n">training</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">mode</span><span class="p">)</span>
        <span class="o">...</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">ground_truth</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">test_loader</span><span class="p">):</span>
        <span class="n">mode</span> <span class="o">=</span> <span class="n">scheduler</span><span class="o">.</span><span class="n">mode</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">net</span><span class="o">.</span><span class="n">training</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">mode</span><span class="p">)</span>
        <span class="o">...</span>
</pre></div>
</div>
<p><strong>Export the network</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">net</span><span class="o">.</span><span class="n">export_hdf5</span><span class="p">(</span><span class="s1">&#39;network.net&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="network-exchange-netx-library">
<h2>Network Exchange (NetX) Library<a class="headerlink" href="#network-exchange-netx-library" title="Permalink to this headline"></a></h2>
<p>For inference using Lava, Network Exchange Library (<cite>lava.lib.dl.netx</cite>) provides an
automated API for loading SLAYER-trained models as Lava Processes, which
can be directly run on a desired backend. <code class="docutils literal notranslate"><span class="pre">lava.lib.dl.netx</span></code> imports
models saved via SLAYER using the hdf5 network exchange format. The
details of hdf5 network description specification can be found
<a class="reference external" href="lava-lib-dl/netx/netx.html">here</a>.</p>
<div class="section" id="example-code-2">
<span id="id2"></span><h3>Example Code<a class="headerlink" href="#example-code-2" title="Permalink to this headline"></a></h3>
<p><strong>Import modules</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">lava.lib.dl.netx</span> <span class="kn">import</span> <span class="n">hdf5</span>
</pre></div>
</div>
<p><strong>Load the trained network</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import the model as a Lava Process</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">hdf5</span><span class="o">.</span><span class="n">Network</span><span class="p">(</span><span class="n">net_config</span><span class="o">=</span><span class="s1">&#39;network.net&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Attach Processes for Input Injection and Output Readout</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">lava.proc.io</span> <span class="kn">import</span> <span class="n">InputLoader</span><span class="p">,</span> <span class="n">BiasWriter</span><span class="p">,</span> <span class="n">OutputReader</span>

<span class="c1"># Instantiate the processes</span>
<span class="n">input_loader</span> <span class="o">=</span> <span class="n">InputLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">testing_set</span><span class="p">)</span>
<span class="n">bias_writer</span> <span class="o">=</span> <span class="n">BiasWriter</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">input_shape</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">OutputReader</span><span class="p">()</span>

<span class="c1"># Connect the input to the network:</span>
<span class="n">input_loader</span><span class="o">.</span><span class="n">data_out</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span><span class="n">bias_writer</span><span class="o">.</span><span class="n">bias_in</span><span class="p">)</span>
<span class="n">bias_writer</span><span class="o">.</span><span class="n">bias_out</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">in_layer</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>

<span class="c1"># Connect network-output to the output process</span>
<span class="n">net</span><span class="o">.</span><span class="n">out_layer</span><span class="o">.</span><span class="n">neuron</span><span class="o">.</span><span class="n">s_out</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">net_output_in</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Run the network</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">lava.magma</span> <span class="kn">import</span> <span class="n">run_configs</span> <span class="k">as</span> <span class="n">rcfg</span>
<span class="kn">from</span> <span class="nn">lava.magma</span> <span class="kn">import</span> <span class="n">run_conditions</span> <span class="k">as</span> <span class="n">rcnd</span>

<span class="n">net</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">condition</span><span class="o">=</span><span class="n">rcnd</span><span class="o">.</span><span class="n">RunSteps</span><span class="p">(</span><span class="n">total_run_time</span><span class="p">),</span> <span class="n">run_cfg</span><span class="o">=</span><span class="n">rcfg</span><span class="o">.</span><span class="n">Loihi1SimCfg</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="detailed-description">
<h2>Detailed Description<a class="headerlink" href="#detailed-description" title="Permalink to this headline"></a></h2>
<div class="toctree-wrapper compound">
<p class="caption" role="heading"><span class="caption-text">Detailed description:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="lava-lib-dl/slayer/slayer.html">Lava-DL SLAYER</a></li>
<li class="toctree-l1"><a class="reference internal" href="lava-lib-dl/bootstrap/bootstrap.html">Lava-DL Bootstrap</a></li>
<li class="toctree-l1"><a class="reference internal" href="lava-lib-dl/netx/netx.html">Lava-DL NetX</a></li>
</ul>
</div>
</div>
</div>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="algorithms.html" class="btn btn-neutral float-left" title="Algorithms and Application Libraries" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="lava-lib-dl/slayer/slayer.html" class="btn btn-neutral float-right" title="Lava-DL SLAYER" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, Intel Corporation.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(false);
      });
  </script> 

</body>
</html>